<!DOCTYPE html>
<html>
  <meta charset="utf-8">
       <meta name="viewport" content="width=device-with", initial- scale="1">
       <link rel="stylesheet" href="style.css">
       <style>

mark { 
  background-color: rgba(0, 0, 0, 0.746);
  color: red;
}
marquee{
width: 100%;
height: 104vh;}

sup {
vertical-align: super;
font-size: 2vw; ;}

.wrapper{
height: 100vh;
overflow: auto;
scroll-snap-type: y mandatory;
}

.section{
  scroll-snap-align: center;
  height: 100vh;
  display: flex;
  background-color: #000000; 
}

.bg-red{
  background: #FF0000;
}
 </style>

  <head>
       <title>MACHINERY X HUMANITY</title>
       <link rel="icon" href="favicon.png" type="image/png">
            </head>

<body>
<div class="wrapper">
<div class="section">
  <h1>
   <br/>
   <br/>
    MACHINERY X HUMANITY</h1>
 </div>
  <div class="content">
     <div class="section bg-red">
      <marquee behavior="scroll" direction="up" scrollamount="5">
          <pre>
           <h3> 
         Machinery x Humanity is a representation
         of an early AI system that analyzes text
         attempting to understand its content.
         Doing so by using different mechanisms
         and fixed rules when the system doesn't
         understant either the meaning or the
         context of the texts it searches through
         the internet what these words mean either
         by definition or images, sometimes making
         one mistakes. No machine is perfect just
         like humans.</h3><h5>
       DATA AND AI SYSTEMS
       PROBLEMS AND THEIR
       REAL CONSEQUENCES</h5>    
         <h3>
         AI systems are extremely integrated into
         today's society, these systems are auto-
         mated machinery that follows strict rule 
         settings It has been well recorded howe-
         vern that even the most well-configured
         systems sometimes demonstrate biased
         and prejudiced results, that in theory
         shouldn't be there, but this isn't
         always true.
            
    
         <b>THE DEMAND FOR  DATA:</b>
    
         “In the 1970s, artificial intelligence
         researchers were mainly exploring what
         is called an expert systems approach: 
         rule-based programming that aims to
         reduce the field of possible actions
         by articulating forms of logical reaso-
         ning. But it quickly became evident that
         this approach was <span><mark>fragile</mark><img src="Definition/fragile.png" class="img"></span>and <span><mark>impractical</mark><img src="Definition/impractical.png" class="img"></span>
         in real-world settings, where a rule set
         was rarely able to handle uncertainty
         and <span><u>complexity</u><img src="photos/complexity.jpg" class="img"></span>. New approaches 
         were needed (...)”  
            
    
         <b>DATA IS NOT NEUTRAL:</b>
         
         “Data is anything but neutral and
         cant be neutralized(...)” [<sup>1</sup>] “They are
         anything but <span><u>neutral</u><img src="photos/neutral.jpg" class="img"></span>. They represent 
         <span><u>personal histories</u><img src="photos/personal histories.jpg" class="img"></span>, structural <mark>inequities</mark>,
         and all the injustices that have accompa-
         nied[...]”[<sup>2</sup>]“The way data is understood,
         captured, <span><mark>classified</mark><img src="Definition/classified.png" class="img"></span>, and named is fun-
         damentally an act of world-making and
         containment. It has enormous ramifica-
         tions for the way artificial intelligence
         works in the world and which commu-
         nities are most affected. The myth of
         data collection as a <span><mark>benevolent</mark><img src="Definition/benevolent.png" class="img"></span> practice
         in computer science has obscured its ope-
         rations of power, protecting those who
         profit most while avoiding responsibility
         for its <span><mark>consequences</mark><img src="Definition/consequence.png" class="img"></span>.”[<sup>2</sup>]
             
         
         <b>BIAS IN AI:</b>
    
         “Bias means a <span><mark>judgment</mark><img src="Definition/judgment.png" class="img"></span> based
         on preconceived notions or <span><u>prejudices</u><img src="photos/prejudice.jpg" class="img"></span>
         as opposed to say the impartial evalua-
         tion of facts” [<sup>1</sup>]  “AI systems
         are shown to produce <span><u>discriminatory</u><img src="photos/discriminatory.jpg" class="img"></span>
         results along the categories of race,
         class, gender, disability, or age,
         companies face considerable pressure to
         reform their tools or diversify their
         data” [<sup>2</sup>] “Discrimination and
         injustice do not come from outside they
         are “in there,” because technological
         defaults are embedded with cultural and
         social prejudices. [...] Every <span><u>dataset</u><img src="photos/dataset.jpg"class="img"></span>
         used to train machine learning systems,
         whether in the context of supervised or
         unsupervised machine learning, whether
         seen to be technically <span><mark>injustice</mark><img src="Definition/injustice.png" class="img"></span> or not,
         contains a worldview.”[<sup>2</sup>]
            
    
         <b>CLASSIFICATION IN AI:</b>
    
         “(...) a core practice in artificial
         intelligence. The practices of classi-
         fication inform how machine intelligence
         is recognized and produced from univer-
         sity labs to the tech industry(...)”[<sup>2</sup>]
         “While some might respond that this can
         be easily remedied by creating more
         categories, this fails to address the
         deeper harm of allocating people into
         gender or race categories without their
         input or consent.''[<sup>2</sup>]  [...]
         how can we redress the <span><u>trauma</u><img src="photos/trauma.jpg" class="img"></span>, discrimi-
         nation, and <span><u>violence</u><img src="photos/violence.jpg" class="img"></span> around us not by
         treating  anyone or any event as “<span><mark>repre-</mark>
         <mark>sentative”</mark><img src="Definition/representative.png" class="img"></span> but rather by acknowledging
         their <span><u>singularity</u><img src="photos/singularity.jpg" class="img"></span> and our resonating
         experiences in our responses?” [<sup>3</sup>]
            
    
         <b>LIMITATIONS OF AI:</b>
    
         “The <span><mark>limitations</mark><img src="Definition/limitation.png" class="img"></span> and <span><mark>vulnerabilities</mark><img src="Definition/vulnerability.png" class="img"></span> of
         technical control systems make it clear
         that <span><u>freedom</u><img src="photos/freedom.jpg" class="img"></span> cannot be reduced to control:
         freedom makes control necessary, but
         never enough.” [<sup>3</sup>]</h3><h5>
       MACHINERY AND DATA-
       RELATED ISSUES</h5><h3>
         The main issue with machinery-type objects
         is mainly two: how these machines lack in
         comparison to humans (be it emotionally or
         mentally) and how information is treated
         by them. These are the problems that will
         possibly never be solved as there are
         extremely complex problems that involve
         social political and economical issues but
         that doesn't mean we should ignore them.
            
    
         <b>MACHINES VS HUMANS:</b>
    
         “Not until a machine can write a sonnet
         or compose a concerto because of thoughts
         and <span><u>emotions</u><img src="photos/Emotions.jpg" class="img"></span> felt, and not by the chance
         fall of symbols, could we agree that
         machine equals brain—that is, not only
         write it but know that it had written it.
         No mechanism could <span><mark>feel</mark><img src="Definition/feel.png" class="img"></span> (and not merely
         artificially signal, an easy contrivance)
         pleasure at its successes, <span><u>grief</u><img src="photos/grief.jpg" class="img"></span> when its
         valves fuse, be warmed by flattery, be made
         miserable by its <span><mark>mistakes</mark><img src="Definition/mistakes.png" class="img"></span>, be charmed by
         sex, be angry or depressed when it cannot
         get what it [<sup>4</sup>]
            
    
         <b>POWER AND LIMITATIONS OF MACHINERY:</b>
    
         “The idea behind digital computers may be
         explained by saying that these machines
         are intended to carry out any operations
         which could be done by a human computer.
         The human computer is supposed to be
         following fixed rules; he has no authority
         to <span><mark>deviate</mark><img src="Definition/deviate.png" class="img"></span> from them in any detail (...)” [<sup>4</sup>]
         “There are a number of results of mathema-
         tical logic which can be used to show that
         there are <span><u>limitations</u><img src="photos/limitations.jpg" class="img"></span> to the powers of
         discrete-state machines.” [<sup>4</sup>] “In short, then,
         there might be  men cleverer than any
         given machine, but then again there might
         be other machines cleverer again, and
         so on.” [<sup>4</sup>]
    
    
         <b>THE PROBLEM WITH INFORMATION:</b>
    
         “Although it makes sense to speak of <span><mark>false</mark><img src="Definition/false.png" class="img"></span>
         information (for example, in a faulty credit
         database), the tacit assumption is most
         commonly that information is true that it
         corresponds in some <span><u>transparent</u><img src="photos/transparent.jpg"class="img"></span> way to
         certain people, places, and things in
         the world.” [<sup>5</sup>]
    
    
         <b>DISTORTION OF INFORMATION:</b>
    
         “(...) no matter how thoroughly the capture
         process is controlled, it is <span><mark>impossible</mark><img src="Definition/impossible.png" class="img"></span>,
         short perhaps of total mechanization of a
         given form of activity, to remove the ele-
         ments of <span><mark>interpretation</mark><img src="Definition/interpretation.png" class="img"></span>, strategy, and ins-
         titutional dynamics.” [<sup>5</sup>] “The point, rather,
         is that capture is never purely technical
         but always sociotechnical in nature.”[<sup>5</sup>]
            
    
         <b>RELEASE OF PRIVATE INFORMATION:</b>
    
         “In space, perhaps, no one can hear you
         scream. But in cyberspace, someone—perhaps
         the richest man on the planet can indeed
         hear you, whether you scream, cry, or whis-
         per, even in a “<span><mark>private</mark><img src="Definition/private.png" class="img"></span>” conversation.”[<sup>5</sup>]</h3>
      </span>
    
    
        <h4>
    1-Kate Crawford, Nips 2017 The Trouble with Bias<p>2-Kate Crawford, Atlas of Ai 2021</p><p>3-Wendy Hui Kyong Chun, Discriminating Data: correlation, neighborhoods, and the new politics of recognition 2021</p><p>4-Alan Turing, Computing Machinery and Intelligence 1950</p><p>5-Agre, Philip E., Surveillance and Capture: Two Models of Privacy,1994 </p>
        </h4>    
               
            </pre>
          </marquee>
</div>
</div>
</body>
</html>
</DOCTYPE>